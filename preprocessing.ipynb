{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "os.environ['TORCH'] = torch.__version__\n",
    "print(torch.__version__)\n",
    "\n",
    "import scipy.io as sio\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from torch_geometric.data import Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Das Proprocessing beruht auf: https://colab.research.google.com/drive/1EBV4eUqUoGpTYqBK2YgHvNtwLjxu1nnc?usp=sharing#scrollTo=Iv1GAxuPtkqI\n",
    "Dataset Download: https://github.com/YingtongDou/CARE-GNN"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "{'__header__': b'MATLAB 5.0 MAT-file Platform: posix, Created on: Wed Aug 19 20:20:49 2020',\n '__version__': '1.0',\n '__globals__': [],\n 'homo': <11944x11944 sparse matrix of type '<class 'numpy.float64'>'\n \twith 8796784 stored elements in Compressed Sparse Column format>,\n 'net_upu': <11944x11944 sparse matrix of type '<class 'numpy.float64'>'\n \twith 351216 stored elements in Compressed Sparse Column format>,\n 'net_usu': <11944x11944 sparse matrix of type '<class 'numpy.float64'>'\n \twith 7132958 stored elements in Compressed Sparse Column format>,\n 'net_uvu': <11944x11944 sparse matrix of type '<class 'numpy.float64'>'\n \twith 2073474 stored elements in Compressed Sparse Column format>,\n 'features': <11944x25 sparse matrix of type '<class 'numpy.float64'>'\n \twith 174488 stored elements in Compressed Sparse Column format>,\n 'label': array([[0., 0., 0., ..., 0., 0., 0.]])}"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Laden des Datensatzes\n",
    "data = sio.loadmat('Data/Amazon.mat', verify_compressed_data_integrity=False)\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 11944)\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "821.0\n"
     ]
    }
   ],
   "source": [
    "# Label überprüfen\n",
    "label = data['label']\n",
    "print(label.shape)\n",
    "print(label)\n",
    "print(label.sum())"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11944, 25)\n",
      "    0     1    2    3    4    5    6    7     8     9   ...   15   16   17  \\\n",
      "0  1.0  26.0  0.0  0.0  0.0  0.0  1.0  0.0  0.00  0.00  ...  5.0  5.0  5.0   \n",
      "1  4.0  17.0  0.0  1.0  1.0  0.0  2.0  0.0  0.25  0.25  ...  4.0  5.0  2.0   \n",
      "2  2.0  15.0  0.0  0.0  0.0  2.0  0.0  0.0  0.00  0.00  ...  4.0  4.0  4.0   \n",
      "3  1.0  21.0  0.0  0.0  0.0  0.0  1.0  0.0  0.00  0.00  ...  5.0  5.0  5.0   \n",
      "4  2.0  18.0  0.0  0.0  0.0  1.0  1.0  0.0  0.00  0.00  ...  4.5  5.0  4.0   \n",
      "\n",
      "     18   19      20        21   22    23   24  \n",
      "0  5.00  0.0     0.0  0.000000  1.0  13.0  1.0  \n",
      "1  3.75  0.0  3382.0  1.386294  0.0  45.0  1.0  \n",
      "2  4.00  0.0     0.0  0.000000  1.0  24.5  1.0  \n",
      "3  5.00  0.0     0.0  0.000000  1.0  14.0  1.0  \n",
      "4  4.50  0.0     0.0  0.000000  1.0  18.5  1.0  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "# Features überprüfen\n",
    "features = data['features']\n",
    "feature_data = pd.DataFrame.sparse.from_spmatrix(features)\n",
    "print(feature_data.shape)\n",
    "print(feature_data.head(5))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# Ermittlung des Kantenindex für drei Netze: upu, usu und uvu\n",
    "net_upu_edges = data['net_upu'].nonzero()\n",
    "net_usu_edges = data['net_usu'].nonzero()\n",
    "net_uvu_edges = data['net_uvu'].nonzero()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "## Verarbeitung des usu-Netzwerks\n",
    "#  Filtert den usu-Graphen auf Knoten mit einem Grad ungleich Null.\n",
    "\n",
    "# In dieser Liste ist der Index der neue Knotenindex und der Wert bei index ist der ursprüngliche Knotenindex.\n",
    "non_zero_degree_nodes_idex = sorted(list(set(net_usu_edges[0].tolist())))\n",
    "\n",
    "# Aufbau des Lookup-Diktats\n",
    "old_index_to_new_index = dict()\n",
    "for idx in range(len(non_zero_degree_nodes_idex)):\n",
    "  old_index_to_new_index[non_zero_degree_nodes_idex[idx]] = idx\n",
    "\n",
    "# Abrufen des neuen x-dataframes\n",
    "usu_x = feature_data.iloc[non_zero_degree_nodes_idex]\n",
    "\n",
    "# Neue Labels\n",
    "usu_label = data['label'][0][non_zero_degree_nodes_idex]\n",
    "\n",
    "\n",
    "# Kanten updaten\n",
    "for i in range(2):\n",
    "  for idx in range(net_usu_edges[0].shape[0]):\n",
    "    net_usu_edges[i][idx] = old_index_to_new_index[net_usu_edges[i][idx]]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train, validation, test split is (7112, 2371, 2371)\n"
     ]
    }
   ],
   "source": [
    "# Erzeugen des Train, Test und Validation Split\n",
    "data_pop = np.arange(usu_label.size)\n",
    "indices = np.random.permutation(data_pop.size)\n",
    "\n",
    "train = int(round(0.6*usu_label.size,0))\n",
    "test = int(round(0.2*usu_label.size,0))\n",
    "\n",
    "train_idx = indices[:train]\n",
    "val_idx = indices[train:train + test]\n",
    "test_idx = indices[train + test:]\n",
    "\n",
    "print(f\"Train, validation, test split is {train_idx.size, val_idx.size, test_idx.size}\")\n",
    "\n",
    "train_array = np.empty([1, usu_label.size])\n",
    "val_array = np.empty([1, usu_label.size])\n",
    "test_array = np.empty([1, usu_label.size])\n",
    "\n",
    "\n",
    "for value in data_pop:\n",
    "  if value in train_idx:\n",
    "    train_array[0][value] = True\n",
    "  else:\n",
    "    train_array[0][value] = False\n",
    "\n",
    "for value in data_pop:\n",
    "  if value in val_idx:\n",
    "    val_array[0][value] = True\n",
    "  else:\n",
    "    val_array[0][value] = False\n",
    "\n",
    "for value in data_pop:\n",
    "  if value in test_idx:\n",
    "    test_array[0][value] = True\n",
    "  else:\n",
    "    test_array[0][value] = False\n",
    "\n",
    "train_final = np.array(train_array[0], dtype=bool)\n",
    "val_final = np.array(val_array[0], dtype=bool)\n",
    "test_final = np.array(test_array[0], dtype=bool)\n",
    "\n",
    "\n",
    "train_mask = torch.Tensor(train_final).bool()\n",
    "val_mask = torch.Tensor(val_final).bool()\n",
    "test_mask = torch.Tensor(test_final).bool()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[11854, 25], edge_index=[2, 7132958], y=[11854], train_mask=[11854], val_mask=[11854], test_mask=[11854])"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Graphen aufsetzen\n",
    "x = torch.tensor(usu_x.values, dtype = torch.float)\n",
    "y = torch.tensor(usu_label, dtype = torch.long)\n",
    "\n",
    "# Kantenindizes aufsetzen\n",
    "edge_index = torch.tensor([net_usu_edges[0], net_usu_edges[1]], dtype=torch.long)\n",
    "\n",
    "usu_graph = Data(x=x, y=y, edge_index=edge_index, train_mask = train_mask, val_mask = val_mask, test_mask = test_mask)\n",
    "torch.save(usu_graph, 'Graph/usu_graph.pth')\n",
    "usu_graph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[11854, 25], edge_index=[2, 7132958], y=[11854], train_mask=[11854], val_mask=[11854], test_mask=[11854])"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.load('Graph/usu_graph.pth')\n",
    "data"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
